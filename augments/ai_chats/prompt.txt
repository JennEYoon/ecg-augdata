I am working on training a deep learning model that will correctly classify ECG signals ouput from a prototype ECG device I am building.  I have very small ouput data from this prototype ECG device.  But I have 100,000 patient data from hospital 12-signal  ECG machines that are publicly available, such as PTB-XL and SPH.

Let's say I want to use these public 12-lead ECG dataset, to create training and test data for a ResNet + SE model to classify ten different types of heart conditions. But instead of hospital-style 12-signal measurements with conductive gel, the data comes from my prototype that has leads embedded into a elastic shirt. It's likely that there will be some displacement of each lead in the shirt from where the lead would be if placed using each patient's fiducials. Also, there will be added noise due to body & shirt movement. How would you augment the public and test data to approximate the displacements and noise from the prototype. Would there be a much larger augmented dataset (using the public dataset as the basis)?